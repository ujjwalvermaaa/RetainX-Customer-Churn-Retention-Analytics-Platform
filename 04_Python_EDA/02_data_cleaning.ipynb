{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edc9589d",
   "metadata": {},
   "source": [
    "# RetainX – Customer Revenue & Subscription Retention Intelligence System  \n",
    "### Data Cleaning & Preprocessing  \n",
    "\n",
    "**Client:** AirWave Communications  \n",
    "**Domain:** Telecom / Subscription Analytics  \n",
    "**Author:** Ujjwal Verma  \n",
    "\n",
    "---\n",
    "\n",
    "## Objective\n",
    "This notebook performs **data cleaning and preprocessing** on the raw telecom customer dataset.\n",
    "\n",
    "Although the source dataset is already complete (no missing values or duplicates), this phase focuses on:\n",
    "- Data type standardization\n",
    "- Outlier treatment\n",
    "- Feature preparation\n",
    "- Ensuring analytics-ready consistency\n",
    "\n",
    "The output of this notebook serves as the **final cleaned dataset** that is ingested into PostgreSQL for SQL-based analytics and modeling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b59eb1a",
   "metadata": {},
   "source": [
    "## 1. Library Imports\n",
    "\n",
    "This section imports the Python libraries required for preprocessing and numerical transformations.\n",
    "\n",
    "- **Pandas** is used for data manipulation and export\n",
    "- **NumPy** is used for numerical operations and outlier handling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72172056",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f4c708",
   "metadata": {},
   "source": [
    "## 2. Load Raw Telecom Customer Dataset\n",
    "\n",
    "The raw telecom customer dataset is loaded from the source CSV file.\n",
    "\n",
    "At this stage:\n",
    "- The dataset is treated as the source of truth\n",
    "- No assumptions are made about downstream analytics\n",
    "- The focus is on preparing the data for analytical modeling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbfd96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../02_Data/raw/telecom_churn.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2132c579",
   "metadata": {},
   "source": [
    "## 3. Data Type Standardization\n",
    "\n",
    "Certain columns are standardized to ensure compatibility with analytical workflows and SQL ingestion:\n",
    "\n",
    "- Registration date is converted to datetime format\n",
    "- Pincode is stored as a string to preserve leading zeros\n",
    "\n",
    "This step prevents downstream inconsistencies and errors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f335fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date_of_registration'] = pd.to_datetime(df['date_of_registration'], errors='coerce')\n",
    "df['pincode'] = df['pincode'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b313b41d",
   "metadata": {},
   "source": [
    "## 4. Duplicate Record Validation\n",
    "\n",
    "Although the dataset does not contain duplicate records, a validation check is performed to confirm data integrity.\n",
    "\n",
    "This is a standard best practice in enterprise analytics pipelines.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abac1ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate rows removed: 0\n"
     ]
    }
   ],
   "source": [
    "initial_count = df.shape[0]\n",
    "df.drop_duplicates(subset=['customer_id'], inplace=True)\n",
    "final_count = df.shape[0]\n",
    "\n",
    "print(\"Duplicate rows removed:\", initial_count - final_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7cb7ee",
   "metadata": {},
   "source": [
    "## 5. Missing Value Validation\n",
    "\n",
    "The dataset is validated for missing values.\n",
    "\n",
    "Since no missing values are present in the source data:\n",
    "- No imputation is required\n",
    "- This step serves as a formal quality check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37f14456",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xl/zg7xr3f931ggd0w1xs4831280000gn/T/ipykernel_70885/3432125287.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/var/folders/xl/zg7xr3f931ggd0w1xs4831280000gn/T/ipykernel_70885/3432125287.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/var/folders/xl/zg7xr3f931ggd0w1xs4831280000gn/T/ipykernel_70885/3432125287.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/var/folders/xl/zg7xr3f931ggd0w1xs4831280000gn/T/ipykernel_70885/3432125287.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/var/folders/xl/zg7xr3f931ggd0w1xs4831280000gn/T/ipykernel_70885/3432125287.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/var/folders/xl/zg7xr3f931ggd0w1xs4831280000gn/T/ipykernel_70885/3432125287.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/var/folders/xl/zg7xr3f931ggd0w1xs4831280000gn/T/ipykernel_70885/3432125287.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/var/folders/xl/zg7xr3f931ggd0w1xs4831280000gn/T/ipykernel_70885/3432125287.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/var/folders/xl/zg7xr3f931ggd0w1xs4831280000gn/T/ipykernel_70885/3432125287.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].mode()[0], inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "customer_id             0\n",
       "telecom_partner         0\n",
       "gender                  0\n",
       "age                     0\n",
       "state                   0\n",
       "city                    0\n",
       "pincode                 0\n",
       "date_of_registration    0\n",
       "num_dependents          0\n",
       "estimated_salary        0\n",
       "calls_made              0\n",
       "sms_sent                0\n",
       "data_used               0\n",
       "churn                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in df.select_dtypes(include=['float64', 'int64']).columns:\n",
    "    df[col].fillna(df[col].median(), inplace=True)\n",
    "\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9317a9d",
   "metadata": {},
   "source": [
    "## 6. Outlier Treatment Using IQR Method\n",
    "\n",
    "Even in clean datasets, extreme values can distort:\n",
    "- Averages\n",
    "- Correlations\n",
    "- Segmentation thresholds\n",
    "\n",
    "The Interquartile Range (IQR) method is applied to cap extreme values while preserving all records.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38699f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "for col in numeric_cols:\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower = Q1 - 1.5 * IQR\n",
    "    upper = Q3 + 1.5 * IQR\n",
    "    df[col] = np.where(df[col] < lower, lower, df[col])\n",
    "    df[col] = np.where(df[col] > upper, upper, df[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02bbea1",
   "metadata": {},
   "source": [
    "## 7. Feature Preparation – Customer Tenure\n",
    "\n",
    "A customer tenure feature (`tenure_months`) is derived using the registration date.\n",
    "\n",
    "This feature is essential for:\n",
    "- Lifecycle segmentation\n",
    "- Churn risk analysis\n",
    "- Retention strategy development\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c69ea87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tenure_months'] = ((pd.Timestamp.now() - df['date_of_registration']).dt.days / 30).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd22627e",
   "metadata": {},
   "source": [
    "## 8. Final Data Quality Validation\n",
    "\n",
    "A final validation check ensures that:\n",
    "- No null values exist\n",
    "- No duplicates were introduced during preprocessing\n",
    "- All derived features are present\n",
    "\n",
    "This confirms readiness for SQL ingestion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c38ac96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Dataset Shape': (243553, 15),\n",
       " 'Null Check': 0,\n",
       " 'Duplicate Count': 0,\n",
       " 'Tenure Created': True}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    " \"Dataset Shape\": df.shape,\n",
    " \"Null Check\": df.isnull().sum().sum(),\n",
    " \"Duplicate Count\": df.duplicated().sum(),\n",
    " \"Tenure Created\": \"tenure_months\" in df.columns\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1502cbfc",
   "metadata": {},
   "source": [
    "## 9. Export Cleaned Dataset for SQL Ingestion\n",
    "\n",
    "The cleaned dataset is exported as a CSV file.\n",
    "\n",
    "This file is used as:\n",
    "- Input for PostgreSQL ingestion\n",
    "- Foundation for SQL-based feature engineering\n",
    "- Single source of truth for analytics and BI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35919d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean dataset exported successfully.\n"
     ]
    }
   ],
   "source": [
    "df.to_csv(\"../02_Data/cleaned_python/telecom_cleaned.csv\", index=False)\n",
    "print(\"Clean dataset exported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47960dd7",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "- The source dataset is clean and well-structured, requiring minimal remediation.\n",
    "- Preprocessing focused on standardization, outlier handling, and feature preparation rather than basic cleaning.\n",
    "- The resulting dataset is analytics-ready and suitable for relational database ingestion.\n",
    "- This notebook acts as the transition point between raw data and SQL-based analytical modeling.\n",
    "\n",
    "---\n",
    "\n",
    "## Next Step\n",
    "\n",
    "The cleaned dataset generated here is ingested into PostgreSQL, where:\n",
    "- Business feature engineering is performed\n",
    "- Customer segmentation is created\n",
    "- Analytical (GOLD) tables are built\n",
    "\n",
    "➡ Proceed to **03_SQL**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
